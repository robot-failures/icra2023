-
  id: 1
  name: "Iman"
  surname: "Awaad"
  company: "Hochschule Bonn-Rhein-Sieg"
  title: "Research associate"
  bio: "TBD"
  abstract: "TBD"
  thumbnailUrl: awaad.png
  rockstar: false
-
  id: 2
  name: "Gerald"
  surname: "Steinbauer-Wagner"
  company: "Graz University of Technology"
  title: "Associate professor"
  bio: "TBD"
  abstract: "TBD"
  thumbnailUrl: steinbauer-wagner.png
  rockstar: false
-
  id: 3
  name: "Sebastian"
  surname: "Blumenthal"
  company: "KELO Robotics GmbH"
  title: "Lead software development engineer"
  bio: "Structured testing - and the surprising failures it can reveal"
  abstract: "Structured testing is vital for the development of robotic applications. KELO Robotics has established a test procedure that includes different types of tests: field tests and endurance tests. A field test is a supervised functional test of the complete system in a real environment. Endurance tests are stress tests for individual components or the overall system. The emphasis in the latter tests is on scalability of test duration while achieving a semi-automated evaluation of performance. Both tests have in common that they are performed over a long period of weeks and months, leading to the detection of failures that might otherwise remain hidden. These types of errors range from degradation of sensing capabilities, to wrong assumptions about the system or environment, and even issues with electromagnetic interference."
  thumbnailUrl: blumenthal.png
  rockstar: false
-
  id: 4
  name: "Marta"
  surname: "Romeo"
  company: "Heriot-Watt University"
  title: "Assistant professor"
  bio: "Failure-in-the-loop HRI: owning mistakes in interaction design"
  abstract: "What constitutes a failure when working with interactions between robots and humans? Can we safely assume that humans do not fail when interacting with each other, and can we demand the same from our robotic systems? With this talk, we will explore the role of failures in human-robot interaction, focusing on demystifying the negative preconception surrounding them. By looking at research from the Interaction Design field, we will differentiate between slips and mistakes, map them to robot errors, and discuss how they can drive the interaction. Owning up to a failure could have consequences on the overall rapport between humans and robots. It has the potential to influence trust and provide a valid method to reshape the expectations that naive users have about the technology, which could ultimately downsize the severity of the failure."
  thumbnailUrl: romeo.png
  rockstar: false
-
  id: 5
  name: "Sonia"
  surname: "Chernova"
  company: "Georgia Institute of Technology"
  title: "Associate professor"
  bio: "TBD"
  abstract: "TBD"
  thumbnailUrl: chernova.png
  rockstar: false
-
  id: 6
  name: "Esra"
  surname: "Erdem"
  company: "Sabanci University"
  title: "Professor"
  bio: "Explainable plan execution monitoring under partial observability"
  abstract: "Successful plan generation for autonomous systems is necessary but not sufficient to guarantee reaching a goal state by an execution of a plan. Various discrepancies between an expected state and the observed state may occur during the plan execution (e.g., due to unexpected exogenous events, changes in the goals, or failure of robot parts) and these discrepancies may lead to plan failures. For that reason, autonomous systems should be equipped with execution monitoring algorithms so that they can autonomously recover from such discrepancies. We introduce a plan execution monitoring algorithm that operates under partial observability. This algorithm relies on novel formal methods for hybrid prediction, diagnosis and explanation generation, and planning. The prediction module generates an expected state after the execution of a part of the plan from an incomplete state to check for discrepancies. The diagnostic reasoning module generates meaningful hypotheses to explain failures of robot parts. Unlike the existing diagnosis methods, the previous hypotheses can be revised, based on new partial observations, increasing the accuracy of explanations as further information becomes available. The replanning module considers these explanations while computing a new plan that would avoid such failures. All these reasoning modules are hybrid in that they combine high-level logical reasoning with low-level feasibility checks based on probabilistic methods. We experimentally show that these hybrid formal reasoning modules improve the performance of plan execution monitoring."
  thumbnailUrl: erdem.png
  rockstar: false
-
  id: 7
  name: "Tathagata"
  surname: "Chakraborti"
  company: "IBM Research AI"
  title: "Research staff member"
  bio: "Plan to Fail or Fail to Plan: An exploration of planning with incomplete knowledge and human expectations"
  abstract: "TBD"
  thumbnailUrl: chakraborti.png
  rockstar: false
-
  id: 8
  name: "Danesh"
  surname: "Tarapore"
  company: "University of Southampton"
  title: "Assistant professor"
  bio: "Resilient robot swarms: from decentralized fault-detection to rapid fault-recovery"
  abstract: "TBD"
  thumbnailUrl: tarapore.png
  rockstar: false
-
  id: 9
  name: "Sanne"
  surname: "van Waveren"
  company: "KTH Royal Institute of Technology"
  title: "Postdoctoral researcher"
  bio: "Towards automatically correcting robot failures using human input"
  abstract: "Robots should adapt their behavior to new situations and people's preferences while ensuring the safety of the robot and its environment. Due to the large number of possible situations robots might encounter, it becomes impractical to define or learn all behaviors prior to deployment, causing the robot to inevitably fail at some point in time. My research focuses on safe human-robot interaction and how we can correct robots in ways that ensure that the robot will do what we tell it to do, e.g., through formal synthesis. In this talk, I will address how we can 1) shield robots from executing high-level actions that would lead to failure states and 2) how we can incorporate people's feedback in motion planning to increase perceived safety of a drone that flies close to people."
  thumbnailUrl: van_waveren.png
  rockstar: false
-
  id: 10
  name: "Masha"
  surname: "Itkina"
  company: "Toyota Research Institute (TRI)"
  title: "Research scientist"
  bio: "TBD"
  abstract: "TBD"
  thumbnailUrl: itkina.png
  rockstar: false
